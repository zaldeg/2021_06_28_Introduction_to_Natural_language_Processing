{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "HW5-colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.5 64-bit"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "9dc16db89c7b7868c1bda26003793495fc53e348f30248cc96f0b4588f8ccbba"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 1"
      ],
      "metadata": {
        "id": "IkpcHsV8RWHA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Написать теггер на данных с руским языком**\n",
        "1. проверить UnigramTagger, BigramTagger, TrigramTagger и их комбмнации\n",
        "2. написать свой теггер как на занятии, попробовать разные векторайзеры, добавить знание не только букв но и слов\n",
        "3. сравнить все реализованные методы сделать выводы\n"
      ],
      "metadata": {
        "id": "aAQBOJRARev7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## загрузка данных"
      ],
      "metadata": {
        "id": "_16J0ER8WOJx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "import pyconll"
      ],
      "outputs": [],
      "metadata": {
        "id": "9wgL-33mWUyZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "# !mkdir datasets"
      ],
      "outputs": [],
      "metadata": {
        "id": "vXxwW9NzW570"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "# !wget -O ./datasets/ru_syntagrus-ud-train.conllu https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-train.conllu\r\n",
        "# !wget -O ./datasets/ru_syntagrus-ud-dev.conllu https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-dev.conllu"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpwgA3svWiRw",
        "outputId": "9d4e2aa6-bcc7-4793-f85d-2ce708f88ff8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "full_train = pyconll.load_from_file('datasets/ru_syntagrus-ud-train.conllu')\r\n",
        "full_test = pyconll.load_from_file('datasets/ru_syntagrus-ud-dev.conllu')"
      ],
      "outputs": [],
      "metadata": {
        "id": "Oymo30RBWjjl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "for sent in full_train[:1]:\r\n",
        "    for token in sent:\r\n",
        "        print(token.form, token.upos)\r\n",
        "    print()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Анкета NOUN\n",
            ". PUNCT\n",
            "\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBzFe82cXGNK",
        "outputId": "3c13d3e6-498a-47bc-e729-d2f953cddfb6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "for sent in full_train[:5]:\r\n",
        "    sentense = [word.form for word in sent]\r\n",
        "    print(' '.join(sentense), end='\\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Анкета .\n",
            "Начальник областного управления связи Семен Еремеевич был человек простой , приходил на работу всегда вовремя , здоровался с секретаршей за руку и иногда даже писал в стенгазету заметки под псевдонимом \" Муха \" .\n",
            "В приемной его с утра ожидали посетители , - кое-кто с важными делами , а кое-кто и с такими , которые легко можно было решить в нижестоящих инстанциях , не затрудняя Семена Еремеевича .\n",
            "Однако стиль работы Семена Еремеевича заключался в том , чтобы принимать всех желающих и лично вникать в дело .\n",
            "Приемная была обставлена просто , но по-деловому .\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "def make_nltk_train(data_conllu):\r\n",
        "    \"\"\"\r\n",
        "    Redo dconllu dataset for nltk taggers\r\n",
        "    input:\r\n",
        "        data_conllu: connllu data\r\n",
        "    return:\r\n",
        "        nltk_data: data (list(list(tupple(word,tag))))\r\n",
        "    \"\"\"\r\n",
        "    nltk_data = []\r\n",
        "\r\n",
        "    for sent in data_conllu:\r\n",
        "        sentence = [(token.form, token.upos) for token in sent]\r\n",
        "        nltk_data.append(sentence)\r\n",
        "        \r\n",
        "    return nltk_data\r\n",
        "    "
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "train = make_nltk_train(full_train)\r\n",
        "test = make_nltk_train(full_test)\r\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "train[:2]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('Анкета', 'NOUN'), ('.', 'PUNCT')],\n",
              " [('Начальник', 'NOUN'),\n",
              "  ('областного', 'ADJ'),\n",
              "  ('управления', 'NOUN'),\n",
              "  ('связи', 'NOUN'),\n",
              "  ('Семен', 'PROPN'),\n",
              "  ('Еремеевич', 'PROPN'),\n",
              "  ('был', 'AUX'),\n",
              "  ('человек', 'NOUN'),\n",
              "  ('простой', 'ADJ'),\n",
              "  (',', 'PUNCT'),\n",
              "  ('приходил', 'VERB'),\n",
              "  ('на', 'ADP'),\n",
              "  ('работу', 'NOUN'),\n",
              "  ('всегда', 'ADV'),\n",
              "  ('вовремя', 'ADV'),\n",
              "  (',', 'PUNCT'),\n",
              "  ('здоровался', 'VERB'),\n",
              "  ('с', 'ADP'),\n",
              "  ('секретаршей', 'NOUN'),\n",
              "  ('за', 'ADP'),\n",
              "  ('руку', 'NOUN'),\n",
              "  ('и', 'CCONJ'),\n",
              "  ('иногда', 'ADV'),\n",
              "  ('даже', 'PART'),\n",
              "  ('писал', 'VERB'),\n",
              "  ('в', 'ADP'),\n",
              "  ('стенгазету', 'NOUN'),\n",
              "  ('заметки', 'NOUN'),\n",
              "  ('под', 'ADP'),\n",
              "  ('псевдонимом', 'NOUN'),\n",
              "  ('\"', 'PUNCT'),\n",
              "  ('Муха', 'NOUN'),\n",
              "  ('\"', 'PUNCT'),\n",
              "  ('.', 'PUNCT')]]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "from nltk.tag import UnigramTagger, BigramTagger, TrigramTagger"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "unigram_tagger = UnigramTagger(train)\r\n",
        "bigram_tagger = BigramTagger(train, backoff=unigram_tagger)\r\n",
        "trigram_tagger = TrigramTagger(train, backoff=unigram_tagger)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "for tagger in (unigram_tagger, bigram_tagger, trigram_tagger):\r\n",
        "    print(f'train: {tagger.evaluate(train)})')\r\n",
        "    print(f'test: {tagger.evaluate(test)})')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: 0.9740030704763828)\n",
            "test: 0.8772537323492737)\n",
            "train: 0.9818043294175962)\n",
            "test: 0.8829828463586425)\n",
            "train: 0.9847095783717296)\n",
            "test: 0.881769622215482)\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "source": [
        "from nltk.tag import TrigramTagger \r\n",
        "\r\n",
        "def backoff_tagger(train_sents, tagger_classes, backoff=None):\r\n",
        "    for cls in tagger_classes:\r\n",
        "        backoff = cls(train_sents, backoff=backoff)\r\n",
        "    return backoff\r\n",
        "\r\n",
        "\r\n",
        "backoff = UnigramTagger(train)\r\n",
        "tag = backoff_tagger(train,  \r\n",
        "                     [BigramTagger, TrigramTagger],  \r\n",
        "                     backoff = backoff) \r\n",
        "  \r\n",
        "tag.evaluate(test) "
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.882081353418933"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "source": [
        "fdata_train = []\r\n",
        "for sent in full_train[:]:\r\n",
        "    fdata_train.append([(token.form, token.upos) for token in sent])\r\n",
        "    \r\n",
        "fdata_test = []\r\n",
        "for sent in full_test[:]:\r\n",
        "    fdata_test.append([(token.form, token.upos) for token in sent])\r\n",
        "    \r\n",
        "fdata_sent_test = []\r\n",
        "for sent in full_test[:]:\r\n",
        "    fdata_sent_test.append([token.form for token in sent])"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "source": [
        "train_tok = []\r\n",
        "train_label = []\r\n",
        "for sent in fdata_train[:]:\r\n",
        "    for tok in sent:\r\n",
        "        train_tok.append(tok[0])\r\n",
        "        train_label.append('NO_TAG' if tok[1] is None else tok[1])\r\n",
        "        \r\n",
        "test_tok = []\r\n",
        "test_label = []\r\n",
        "for sent in fdata_test[:]:\r\n",
        "    for tok in sent:\r\n",
        "        test_tok.append(tok[0])\r\n",
        "        test_label.append('NO_TAG' if tok[1] is None else tok[1])"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer, HashingVectorizer\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "source": [
        "le = LabelEncoder()\r\n",
        "train_enc_labels = le.fit_transform(train_label)\r\n",
        "test_enc_labels = le.transform(test_label)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(ngram_range=(2, 8),  analyzer='char')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "source": [
        "X_train = tfidf_vectorizer.fit_transform(train_tok)\r\n",
        "X_test = tfidf_vectorizer.transform(test_tok)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "source": [
        "lr = LogisticRegression(n_jobs=-1, penalty='l2')\r\n",
        "lr.fit(X_train, train_enc_labels)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(n_jobs=-1)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "source": [
        "pred = lr.predict(X_test)\r\n",
        "accuracy_score(test_enc_labels, pred)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8453391972500253"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Не понимаю как на уроке получилось что общаая модель справилась лучше, по сути она имеет меньший биас чем модели по отдельности. видимо в моем случае биаса у моделей нету почти. Свой теггер вроде как справился лучше остальных. Tfidf, справился лучше чем CountVectorizer, возможно из за того что данные в CountVectorizere не нормированы, а может и из за самого подхода. В своем тегере попробовал взять lightgbm, но размеры данных слишком большие что бы строить деревья."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задание 2"
      ],
      "metadata": {
        "id": "cINqgGpKXURp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "много дополнительных датасетов на русском языке\n",
        "\n",
        "https://natasha.github.io/corus/  \n",
        "https://github.com/natasha/corus"
      ],
      "metadata": {
        "id": "VCM0drjKXYet"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "мы будем использовать данные http://www.labinform.ru/pub/named_entities/"
      ],
      "metadata": {
        "id": "sUOg4C8sZNpw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Проверить насколько хорошо работает NER**\n",
        "\n",
        "1. взять нер из nltk\n",
        "2. проверить deeppavlov\n",
        "3. написать свой нер попробовать разные подходы:\n",
        "* передаём в сетку токен и его соседей\n",
        "* передаём в сетку только токен\n",
        "\n",
        "4. сделать выводы по вашим экспериментам какой из подходов успешнее справляется"
      ],
      "metadata": {
        "id": "qzi6ApNLZg6X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "при обучении своего нера незабудьте разделить выборку"
      ],
      "metadata": {
        "id": "aP1LgaNUtaOz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "source": [
        "import corus"
      ],
      "outputs": [],
      "metadata": {
        "id": "hrc5ocDkaS1e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "source": [
        "from corus import load_ne5\r\n",
        "\r\n",
        "dir = 'Collection5/'\r\n",
        "records = load_ne5(dir)\r\n"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEdS2pAS3fod",
        "outputId": "402714b1-6931-41ce-ef39-f68080d9a29e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "процедуры обработки взять из вебинарного ноутбука"
      ],
      "metadata": {
        "id": "GrhLNgNwQP2P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "source": [
        "import nltk\r\n",
        "nltk.download('maxent_ne_chunker')\r\n",
        "nltk.download('words')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     C:\\Users\\zald\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to\n",
            "[nltk_data]     C:\\Users\\zald\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "source": [
        "documents = list(records)\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "uRuODJpkIqlv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "source": [
        "document = documents[1]"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "source": [
        "document.text"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Комиссар СЕ критикует ограничительную политику в отношении беженцев в европейских странах\\r\\n\\r\\n05/08/2008 10:32\\r\\n\\r\\nМОСКВА, 5 августа /Новости-Грузия/.  Проводимая в европейских странах ограничительная политика в отношении беженцев нарушает ряд международных стандартов, в частности, право на воссоединение семей, заявляет Комиссар Совета Европы по правам человека Томас Хаммарберг (Thomas Hammarberg) в размещенном на его сайте еженедельном комментарии.\\r\\n\\r\\n\"Ограничительная политика в отношении беженцев в европейских странах уменьшает возможности воссоединения разделенных семей\", - полагает он.\\r\\n\\r\\nПо сообщению РИА Новости, Хаммарберг констатирует, что в последнее время \"правительства попытались ограничить приезд близких родственников к тем беженцам, которые уже проживают в стране\".\\r\\n\\r\\nКомиссар не называет конкретных стран, одновременно отмечая, что в ряде случаев подобная линия привела \"к неоправданным человеческим страданиям, когда члены семьи, зависящие друг от друга, оказались разделенными\".\\r\\n\\r\\n\"Такая политика противоречит праву на воссоединение семей, как это предусмотрено некоторыми международными стандартами\", - замечает он.\\r\\n\\r\\nКомиссар Совета Европы призывает страны учитывать в политике, проводимой в отношении беженцев, положения о семье, принятые в рамках ООН и ЕС.'"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "source": [
        "{(' '.join(c[0] for c in chunk), chunk.label() ) for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(document.text))) if hasattr(chunk, 'label') }"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('Thomas Hammarberg', 'PERSON'),\n",
              " ('Комиссар', 'PERSON'),\n",
              " ('МОСКВА', 'ORGANIZATION'),\n",
              " ('РИА Новости', 'ORGANIZATION'),\n",
              " ('СЕ', 'ORGANIZATION'),\n",
              " ('Совета Европы', 'PERSON'),\n",
              " ('Хаммарберг', 'PERSON')}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пожалуйста если есть возможность не пишите таких выражений они практически не читаемы. И да, NER от nltk такой себе =)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "deeppavlov не установился ни сюда ни в venv. ему там много всего не нравится."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "source": [
        "from corus import load_ne5\r\n",
        "\r\n",
        "dir = 'Collection5/'\r\n",
        "records = load_ne5(dir)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "source": [
        "from razdel import tokenize\r\n",
        "import pandas as pd"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "source": [
        "words_docs = []\r\n",
        "for ix, rec in enumerate(records):\r\n",
        "    words = []\r\n",
        "    for token in tokenize(rec.text):\r\n",
        "        type_ent = 'OUT'\r\n",
        "        for ent in rec.spans:\r\n",
        "            if (token.start >= ent.start) and (token.stop <= ent.stop):\r\n",
        "                type_ent = ent.type\r\n",
        "                break\r\n",
        "        words.append([token.text, type_ent])\r\n",
        "    words_docs.extend(words)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "source": [
        "df_words = pd.DataFrame(words_docs, columns=['word', 'tag'])"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "source": [
        "df_words['tag'].value_counts()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OUT         219214\n",
              "PER          21200\n",
              "ORG          13651\n",
              "LOC           4568\n",
              "GEOPOLIT      4356\n",
              "MEDIA         2482\n",
              "Name: tag, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "source": [
        "df_words.head(3)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           word       tag\n",
              "0        Россия  GEOPOLIT\n",
              "1  рассчитывает       OUT\n",
              "2            на       OUT"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Россия</td>\n",
              "      <td>GEOPOLIT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>рассчитывает</td>\n",
              "      <td>OUT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>на</td>\n",
              "      <td>OUT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "source": [
        "df_words.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(265471, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "source": [
        "import tensorflow as tf\r\n",
        "\r\n",
        "from tensorflow.keras import Sequential\r\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D, GlobalMaxPooling1D, Conv1D, GRU, LSTM, Dropout, Input\r\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "source": [
        "from sklearn import model_selection, preprocessing, linear_model\r\n",
        "\r\n",
        "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(df_words['word'], df_words['tag'])\r\n",
        "\r\n",
        "# labelEncode целевую переменную\r\n",
        "encoder = preprocessing.LabelEncoder()\r\n",
        "train_y = encoder.fit_transform(train_y)\r\n",
        "valid_y = encoder.fit_transform(valid_y)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "source": [
        "train_x.apply(len).max(axis=0)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "source": [
        "valid_x"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "89631           Президент\n",
              "265315                  ,\n",
              "41557                   о\n",
              "32201                   ,\n",
              "77144                   Ю\n",
              "               ...       \n",
              "236833                все\n",
              "256401    припаркованного\n",
              "226178           входящих\n",
              "53421                   ,\n",
              "9276            Президент\n",
              "Name: word, Length: 66368, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "source": [
        "train_data = tf.data.Dataset.from_tensor_slices((train_x, train_y))\r\n",
        "valid_data = tf.data.Dataset.from_tensor_slices((valid_x, valid_y))\r\n",
        "\r\n",
        "train_data = train_data.batch(16)\r\n",
        "valid_data = valid_data.batch(16)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\r\n",
        "\r\n",
        "train_data = train_data.cache().prefetch(buffer_size=AUTOTUNE)\r\n",
        "valid_data = valid_data.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "source": [
        "def custom_standardization(input_data):\r\n",
        "    return input_data\r\n",
        "\r\n",
        "vocab_size = 30000\r\n",
        "seq_len = 10\r\n",
        "\r\n",
        "vectorize_layer = TextVectorization(\r\n",
        "    standardize=custom_standardization,\r\n",
        "    max_tokens=vocab_size,\r\n",
        "    output_mode='int',\r\n",
        "    #ngrams=(1, 3),\r\n",
        "    output_sequence_length=seq_len)\r\n",
        "\r\n",
        "# Make a text-only dataset (no labels) and call adapt to build the vocabulary.\r\n",
        "text_data = train_data.map(lambda x, y: x)\r\n",
        "vectorize_layer.adapt(text_data)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "source": [
        "embedding_dim = 64\r\n",
        "\r\n",
        "class modelNER(tf.keras.Model):\r\n",
        "    def __init__(self):\r\n",
        "        super(modelNER, self).__init__()\r\n",
        "        self.emb = Embedding(vocab_size, embedding_dim)\r\n",
        "        self.gPool = GlobalMaxPooling1D()\r\n",
        "        self.fc1 = Dense(300, activation='relu')\r\n",
        "        self.fc2 = Dense(50, activation='relu')\r\n",
        "        self.fc3 = Dense(6, activation='softmax')\r\n",
        "\r\n",
        "    def call(self, x):\r\n",
        "        x = vectorize_layer(x)\r\n",
        "        x = self.emb(x)\r\n",
        "        pool_x = self.gPool(x)\r\n",
        "        \r\n",
        "        fc_x = self.fc1(pool_x)\r\n",
        "        fc_x = self.fc2(fc_x)\r\n",
        "        \r\n",
        "        concat_x = tf.concat([pool_x, fc_x], axis=1)\r\n",
        "        prob = self.fc3(concat_x)\r\n",
        "        return prob"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "source": [
        "mmodel = modelNER()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "source": [
        "mmodel.compile(optimizer='adam',\r\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\r\n",
        "              metrics=['accuracy'])"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "source": [
        "mmodel.fit(train_data, validation_data=valid_data, epochs=3)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "12444/12444 [==============================] - 225s 18ms/step - loss: 0.1390 - accuracy: 0.9565 - val_loss: 0.2395 - val_accuracy: 0.8859\n",
            "Epoch 2/3\n",
            "12444/12444 [==============================] - 213s 17ms/step - loss: 0.1270 - accuracy: 0.9583 - val_loss: 0.2276 - val_accuracy: 0.9346\n",
            "Epoch 3/3\n",
            "12444/12444 [==============================] - 266s 21ms/step - loss: 0.1224 - accuracy: 0.9589 - val_loss: 0.2400 - val_accuracy: 0.9342\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x2a6e0ea10d0>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Совершенно непонятно как это все работает, Для чего тут embeding слой, зачем тут maxpooling (просто для сокращения количствва данных?) Как построить другую форму сети по словам. Все это совершенно неочевидно. И по общей форме имеет мало отношения к курсу по изображениям. Для нас сетки это темный лес. Мы все проскакивали по верхам, без глобального разборы самого тензор флоу. В основном у нас были алгоритмы а не их реализация. И тут слои по сути конечно похожи но как точно они работают со словами непонятно. Если курс расчитан на то что вы за лецию показывает 10 библиотек по 10 мнут на каждую, я дома должен разобраться в их работе. То это как мне кажется чушь а не обучение.  Ямогу разобраться в том как подкрутить эту сетку, но у меня реально уйдет на это неделая, просто прочитать как все это работает по отдельности, и потыркаться на разных примеров. Учитывя то что сам Tensorflow сам по себе почти безразмерный. Чето накипело, простите."
      ],
      "metadata": {}
    }
  ]
}